{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdjVtLYL6sXJ",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_QSfQu7arNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SWITCH TO GPU\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import torch \n",
        "\n",
        "SEED = 15\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4lXNDq6njd",
        "colab_type": "text"
      },
      "source": [
        "# Get the data from github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0g6YMvNcFUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/w-is-h/tmp/master/dataset.csv\", encoding='cp1252')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YALrViGcIQ7",
        "colab_type": "code",
        "outputId": "44a224f0-0744-4627-8ab6-1e45ef425154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentimentText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first think another Disney movie, might good, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Put aside Dr. House repeat missed, Desperate H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>big fan Stephen King's work, film made even gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watched horrid thing TV. Needless say one movi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>truly enjoyed film. acting terrific plot. Jeff...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       SentimentText  Sentiment\n",
              "0  first think another Disney movie, might good, ...          1\n",
              "1  Put aside Dr. House repeat missed, Desperate H...          0\n",
              "2  big fan Stephen King's work, film made even gr...          1\n",
              "3  watched horrid thing TV. Needless say one movi...          0\n",
              "4  truly enjoyed film. acting terrific plot. Jeff...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO8wGAHN6uMq",
        "colab_type": "text"
      },
      "source": [
        "# Print some statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqoppNTg6xzu",
        "colab_type": "code",
        "outputId": "baf1950f-842a-42ce-bf4d-639ec23e28b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# TODO: Print the shape, columns and the number of positive values in our dataset\n",
        "shape = df.shape\n",
        "cols = list(df.columns) # Must be a list\n",
        "num_pos = np.sum(df['Sentiment'])\n",
        "print(\"The shape of the dataset is: \" + str(shape))\n",
        "print(\"The columns are: \" + str(cols))\n",
        "print(\"Number of positive values: \" + str(num_pos))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the dataset is: (25000, 2)\n",
            "The columns are: ['SentimentText', 'Sentiment']\n",
            "Number of positive values: 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YadlC2_cMzc",
        "colab_type": "code",
        "outputId": "2bcb7688-a96b-4e94-e794-e1ce78130f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# TODO: using 'plt' plot a histogram for the column Sentiment\n",
        "_ = plt.hist(df['Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaVcTC417YI8",
        "colab_type": "text"
      },
      "source": [
        "###Get the $x,y$ values from the datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa66fNKWd2lT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df['SentimentText'].values\n",
        "y = df['Sentiment'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sErAVeYuduCx",
        "colab_type": "text"
      },
      "source": [
        "###Look at x and check do we need to clean anything\n",
        "\n",
        "Cleaning is not always necessary, but the more garbage we leave the more the Neural Network has to learn. So, if the cleaning process is easy - better to do it. Or get a gigantic dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO4wpcINdWMz",
        "colab_type": "code",
        "outputId": "ada4b07c-1745-4df6-dbd9-3ac2d06b6793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(x[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "watched horrid thing TV. Needless say one movies watch see much worse get. Frankly, don't know much lower bar go. <br /><br />The characters composed one lame stereo-type another, obvious attempt creating another \"Bad News Bears\" embarrassing say least.<br /><br />I seen prized turkeys time, reason list since \"Numero Uno\".<br /><br />Let put way, watched Vanilla Ice movie, bad funny. This...this...is even good.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9rNmcu6fpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove mails and https links\n",
        "pat_1 = r\"(?:\\@|https?\\://)\\S+\"\n",
        "# Remove tags\n",
        "pat_2 = r'#\\w+ ?'\n",
        "# Combine into one regex\n",
        "combined_pat = r'|'.join((pat_1, pat_2))\n",
        "# Remove websites\n",
        "www_pat = r'www.[^ ]+'\n",
        "# Remove HTML tags\n",
        "html_tag = r'<[^>]+>'\n",
        "def data_cleaner(text):\n",
        "  cleantags = \"\"\n",
        "  try:\n",
        "    stripped = re.sub(combined_pat, '', text)\n",
        "    stripped = re.sub(www_pat, '', stripped)\n",
        "    cleantags = re.sub(html_tag, '', stripped)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    cleantags = \"None\"\n",
        "  return cleantags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98OEBCta7Os0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Run the cleaning function for each sentence in 'x' and save the results into a\n",
        "#new variable x2\n",
        "x2 = []\n",
        "for doc in x:\n",
        "  x2.append(data_cleaner(doc))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoQ0ndefe_IF",
        "colab_type": "code",
        "outputId": "592b2e8d-a35d-40a3-9902-1150cb479329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x_original = x\n",
        "x = x2\n",
        "print(x[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "watched horrid thing TV. Needless say one movies watch see much worse get. Frankly, don't know much lower bar go. The characters composed one lame stereo-type another, obvious attempt creating another \"Bad News Bears\" embarrassing say least.I seen prized turkeys time, reason list since \"Numero Uno\".Let put way, watched Vanilla Ice movie, bad funny. This...this...is even good.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z75yCgk-7wLa",
        "colab_type": "text"
      },
      "source": [
        "# SpaCy\n",
        "\n",
        "We can use spacy to tokenize the text and further clean it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmE8oH7KbonG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.attrs import LOWER\n",
        "# Load the english model for spacy, the disable part is used to make it faster\n",
        "nlp = spacy.load('en', disable=['ner', 'parser'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3Jz7Ql5jCKr",
        "colab_type": "text"
      },
      "source": [
        "###The nlp variable is an instance of a class that has the method \\_\\_call__ defined, which means it is a class that is callable\n",
        "\n",
        "It returns an object that is a spacy representation of the input sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iccllc0l7zHG",
        "colab_type": "code",
        "outputId": "cbdd9f9d-5ddc-420c-82b0-0981b37374b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(\"Type of the nlp variable is: \" + str(type(nlp)))\n",
        "doc = nlp(\"I was running yesterday.\")\n",
        "print(\"\\nThe 'nlp' function returns: \" + str(type(doc)))\n",
        "print(\"\\nIf we print the 'doc' variable we get the original input sentence: \" + str(doc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of the nlp variable is: <class 'spacy.lang.en.English'>\n",
            "\n",
            "The 'nlp' function returns: <class 'spacy.tokens.doc.Doc'>\n",
            "\n",
            "If we print the 'doc' variable we get the original input sentence: I was running yesterday.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2gPwleAkTXb",
        "colab_type": "text"
      },
      "source": [
        "###To access tokens we can loop over the document - this means the 'doc' class has an \\_\\_iter__ method defined\n",
        "\n",
        "Look [here](https://github.com/explosion/spaCy/blob/9003fd25e5e966bd8d1b67a18f3ebd6010d6f718/spacy/tokens/doc.pyx) for the class definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2shYPjFX75Gq",
        "colab_type": "code",
        "outputId": "f1fb3642-d5bc-4d79-c5a1-93917afb8a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for token in doc:\n",
        "  print(token)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I\n",
            "was\n",
            "running\n",
            "yesterday\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap-m0CAgoddy",
        "colab_type": "text"
      },
      "source": [
        "###Note that each token is a spacy object - not a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xicuAf3qoj_K",
        "colab_type": "code",
        "outputId": "21960086-a237-4f22-db00-132252d46ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(doc[0])) # we can also index the doc object and get tokens"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_ja7vJ3omkQ",
        "colab_type": "text"
      },
      "source": [
        "###To get strings we use the .text property"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw9y7IEeoq6W",
        "colab_type": "code",
        "outputId": "6800fb89-18fb-4a57-c3de-ef5d8b7c5a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(doc[0].text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzY4iHv18CVt",
        "colab_type": "code",
        "outputId": "fbba22c4-1b53-4054-846d-90b6dfc2e74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Each token has multiple properties, e.g. lemma_ - note the '_', that means print text\n",
        "for token in doc:\n",
        "  print(token.lemma_)\n",
        "  print(token.is_stop)\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-PRON-\n",
            "True\n",
            "\n",
            "be\n",
            "True\n",
            "\n",
            "run\n",
            "False\n",
            "\n",
            "yesterday\n",
            "False\n",
            "\n",
            ".\n",
            "False\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXbv-Df64G50",
        "colab_type": "code",
        "outputId": "1933f256-ad6d-4bee-d03b-1dd0f3b742d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "snt = \"That was a very good movie, John\"\n",
        "# TODO: Tokenize the sentence above and save the lemmatized strings into the \n",
        "#tmp variable\n",
        "\n",
        "tmp = [t.lemma_ for t in nlp(snt)]\n",
        "print(tmp)\n",
        "# The output should be ['that', 'be', 'a', 'very', 'good', 'movie', ',', 'John']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['that', 'be', 'a', 'very', 'good', 'movie', ',', 'John']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUpxGw6vo2su",
        "colab_type": "code",
        "outputId": "83562381-a9e4-492e-b7f4-5e729e0f2407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO: Tokenize the sentence again and save the lemmatized strings into the \n",
        "#tmp variable, but skip stopwords and punctuation plus lowercase the lemmas, \n",
        "#print the tmp variable\n",
        "tmp = [t.lemma_.lower() for t in nlp(snt) if not t.is_stop and not t.is_punct]\n",
        "print(tmp)\n",
        "# The output should be ['good', 'movie', 'john']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['good', 'movie', 'john']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ykAaAne8KVb",
        "colab_type": "text"
      },
      "source": [
        "# Split sentences into tokens and lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81ry5hpe8XGp",
        "colab_type": "code",
        "outputId": "e234f16d-8c6f-4ac6-e3cc-bbc6537d8eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Print the first sentence\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYR6ueKeWz6",
        "colab_type": "code",
        "outputId": "fe9e4e19-1762-4e58-8c12-1bb949ef7550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# TODO: Lemmatize and split each sentence in our dataset 'x', save the new\n",
        "#lemmatized strings into the tok_snts variable. Skip punctuation and stopwords plus lowercase lemmas\n",
        "tok_snts = []\n",
        "for snt in x:\n",
        "  tkns = [tkn.lemma_.lower() for tkn in nlp(snt) if not tkn.is_punct and not tkn.is_stop]\n",
        "  tok_snts.append(tkns)\n",
        "# Save back\n",
        "x = tok_snts\n",
        "# Print the first sentence\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['think', 'disney', 'movie', 'good', 'kid', 'movie', 'watch', 'help', 'enjoy', 'age', 'love', 'movie', 'see', 'movie', '10', '8', 'year', 'later', 'love', 'danny', 'glover', 'superb', 'play', 'better', 'christopher', 'lloyd', 'hilarious', 'perfect', 'tony', 'danza', 'believable', 'mel', 'clark', 'help', 'enjoy', 'movie', '10/10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQc1FRv48n9J",
        "colab_type": "text"
      },
      "source": [
        "# Train word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVSxGpV4cOx8",
        "colab_type": "code",
        "outputId": "f506b695-7169-4bad-f87d-820c7185f9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1224
        }
      },
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Basic configuration for logging - needed for gensim to print some output\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "w2v = Word2Vec(x, size=300, window=6, min_count=4, workers=4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-25 09:54:53,935 : INFO : 'pattern' package not found; tag filters are not available for English\n",
            "2019-06-25 09:54:53,945 : INFO : collecting all words and their counts\n",
            "2019-06-25 09:54:53,946 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-06-25 09:54:54,218 : INFO : PROGRESS: at sentence #10000, processed 1068953 words, keeping 52119 word types\n",
            "2019-06-25 09:54:54,497 : INFO : PROGRESS: at sentence #20000, processed 2117054 words, keeping 74728 word types\n",
            "2019-06-25 09:54:54,634 : INFO : collected 83742 word types from a corpus of 2633298 raw words and 25000 sentences\n",
            "2019-06-25 09:54:54,635 : INFO : Loading a fresh vocabulary\n",
            "2019-06-25 09:54:54,733 : INFO : effective_min_count=4 retains 27093 unique words (32% of original 83742, drops 56649)\n",
            "2019-06-25 09:54:54,735 : INFO : effective_min_count=4 leaves 2558477 word corpus (97% of original 2633298, drops 74821)\n",
            "2019-06-25 09:54:54,850 : INFO : deleting the raw counts dictionary of 83742 items\n",
            "2019-06-25 09:54:54,854 : INFO : sample=0.001 downsamples 31 most-common words\n",
            "2019-06-25 09:54:54,855 : INFO : downsampling leaves estimated 2406272 word corpus (94.1% of prior 2558477)\n",
            "2019-06-25 09:54:54,942 : INFO : estimated required memory for 27093 words and 300 dimensions: 78569700 bytes\n",
            "2019-06-25 09:54:54,943 : INFO : resetting layer weights\n",
            "2019-06-25 09:54:55,360 : INFO : training model with 4 workers on 27093 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
            "2019-06-25 09:54:56,373 : INFO : EPOCH 1 - PROGRESS: at 12.09% examples, 297903 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-25 09:54:57,381 : INFO : EPOCH 1 - PROGRESS: at 25.67% examples, 310640 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:54:58,420 : INFO : EPOCH 1 - PROGRESS: at 40.41% examples, 323525 words/s, in_qsize 7, out_qsize 1\n",
            "2019-06-25 09:54:59,423 : INFO : EPOCH 1 - PROGRESS: at 55.91% examples, 334913 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:00,480 : INFO : EPOCH 1 - PROGRESS: at 71.22% examples, 336705 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:01,508 : INFO : EPOCH 1 - PROGRESS: at 86.32% examples, 339290 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:02,348 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-25 09:55:02,367 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-25 09:55:02,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-25 09:55:02,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-25 09:55:02,378 : INFO : EPOCH - 1 : training on 2633298 raw words (2406607 effective words) took 7.0s, 343421 effective words/s\n",
            "2019-06-25 09:55:03,420 : INFO : EPOCH 2 - PROGRESS: at 13.98% examples, 332057 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:04,424 : INFO : EPOCH 2 - PROGRESS: at 28.97% examples, 346511 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:05,492 : INFO : EPOCH 2 - PROGRESS: at 44.12% examples, 346647 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:06,518 : INFO : EPOCH 2 - PROGRESS: at 59.93% examples, 352523 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:07,525 : INFO : EPOCH 2 - PROGRESS: at 73.76% examples, 346987 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:08,601 : INFO : EPOCH 2 - PROGRESS: at 88.60% examples, 343753 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:09,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-25 09:55:09,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-25 09:55:09,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-25 09:55:09,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-25 09:55:09,344 : INFO : EPOCH - 2 : training on 2633298 raw words (2406084 effective words) took 7.0s, 345744 effective words/s\n",
            "2019-06-25 09:55:10,374 : INFO : EPOCH 3 - PROGRESS: at 13.57% examples, 327608 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:11,399 : INFO : EPOCH 3 - PROGRESS: at 28.62% examples, 340685 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:12,413 : INFO : EPOCH 3 - PROGRESS: at 42.58% examples, 340153 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:13,450 : INFO : EPOCH 3 - PROGRESS: at 58.15% examples, 344621 words/s, in_qsize 7, out_qsize 1\n",
            "2019-06-25 09:55:14,471 : INFO : EPOCH 3 - PROGRESS: at 73.41% examples, 346751 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:15,479 : INFO : EPOCH 3 - PROGRESS: at 87.10% examples, 342878 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-25 09:55:16,345 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-25 09:55:16,371 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-25 09:55:16,406 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-25 09:55:16,414 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-25 09:55:16,416 : INFO : EPOCH - 3 : training on 2633298 raw words (2406436 effective words) took 7.1s, 340632 effective words/s\n",
            "2019-06-25 09:55:17,455 : INFO : EPOCH 4 - PROGRESS: at 13.98% examples, 340189 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:18,442 : INFO : EPOCH 4 - PROGRESS: at 28.97% examples, 351018 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:19,444 : INFO : EPOCH 4 - PROGRESS: at 43.34% examples, 351342 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:20,483 : INFO : EPOCH 4 - PROGRESS: at 58.84% examples, 352772 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:21,501 : INFO : EPOCH 4 - PROGRESS: at 74.50% examples, 355334 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:22,533 : INFO : EPOCH 4 - PROGRESS: at 90.06% examples, 356098 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:23,112 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-25 09:55:23,114 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-25 09:55:23,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-25 09:55:23,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-25 09:55:23,149 : INFO : EPOCH - 4 : training on 2633298 raw words (2406347 effective words) took 6.7s, 358097 effective words/s\n",
            "2019-06-25 09:55:24,162 : INFO : EPOCH 5 - PROGRESS: at 14.38% examples, 350545 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:25,215 : INFO : EPOCH 5 - PROGRESS: at 29.36% examples, 347442 words/s, in_qsize 8, out_qsize 0\n",
            "2019-06-25 09:55:26,239 : INFO : EPOCH 5 - PROGRESS: at 44.45% examples, 352227 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:27,293 : INFO : EPOCH 5 - PROGRESS: at 59.98% examples, 352131 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-25 09:55:28,299 : INFO : EPOCH 5 - PROGRESS: at 74.14% examples, 348527 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-25 09:55:29,349 : INFO : EPOCH 5 - PROGRESS: at 89.30% examples, 347931 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-25 09:55:29,965 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-25 09:55:30,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-25 09:55:30,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-25 09:55:30,026 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-25 09:55:30,027 : INFO : EPOCH - 5 : training on 2633298 raw words (2405670 effective words) took 6.9s, 350079 effective words/s\n",
            "2019-06-25 09:55:30,030 : INFO : training on a 13166490 raw words (12031144 effective words) took 34.7s, 347042 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NpMdj6WIUvS",
        "colab_type": "text"
      },
      "source": [
        "#Similarity\n",
        "\n",
        "We can now easily calculate word similarity using the `w2v.wv.most_similar()` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KyOvtimcsdh",
        "colab_type": "code",
        "outputId": "b73b57cf-3144-4c9f-851f-049411258e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "w2v.wv.most_similar(\"bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-25 09:55:30,041 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('worst', 0.8237829208374023),\n",
              " ('horrible', 0.7980390191078186),\n",
              " ('terrible', 0.7953283786773682),\n",
              " ('suck', 0.7761963605880737),\n",
              " ('awful', 0.7734248638153076),\n",
              " ('possibly', 0.7321049571037292),\n",
              " ('lousy', 0.714869499206543),\n",
              " ('worse', 0.7080152034759521),\n",
              " ('crappy', 0.6977818012237549),\n",
              " ('lame', 0.6854100823402405)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMdm2yTIHmM",
        "colab_type": "text"
      },
      "source": [
        "#Get vectors\n",
        "\n",
        "To get a vector for a word 'w' we can use the `w2v.wv.get_vector(w)` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU_X_Wb48tGW",
        "colab_type": "code",
        "outputId": "d0f59145-89f6-483c-a805-278d44cceeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "#To check is a word in our vocab we use:\n",
        "if 'bad' in w2v.wv:\n",
        "  print(w2v.wv.get_vector(\"bad\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.20606323  1.3679227   0.6210256  -1.8426057   1.0910314   0.49461135\n",
            " -0.35775855 -1.3945628  -0.19248852 -0.3548711   0.0883837  -0.42080787\n",
            " -0.06015233  0.5568484  -1.1982398  -0.962829   -0.49825323 -0.790805\n",
            " -1.0691336  -0.6467634  -0.3542181   1.1681327   0.78733665  0.11711236\n",
            "  0.8981934  -1.0393045  -0.22445396  0.7769544   0.44682854  0.36421224\n",
            " -0.7480011   0.79511076 -0.1325793  -0.29321134  0.8712999   0.7578471\n",
            "  0.31934336 -0.13637286  0.62699115  0.49465156  0.42198205  0.16660051\n",
            " -0.31003457  0.735745    0.02922532 -0.0129219  -1.1790099   0.00681409\n",
            " -0.7079715   0.18703519  0.28941944  0.21530084 -0.10562854  0.85863453\n",
            " -0.52595544 -0.10525871  0.25151446 -0.18472372  0.85094064 -1.314031\n",
            " -0.07612921  0.2842826   0.09997708 -1.0896975   0.37234488  0.48612958\n",
            "  0.23525228  0.82082206 -0.73600215  0.9584411   0.90113777 -0.22174488\n",
            " -0.00359149  0.09651064  0.23238002  0.44414145 -0.50571036  0.59870267\n",
            "  1.1984115  -0.24825507  0.81835485 -0.57639414 -0.49300018 -0.74173814\n",
            " -0.09765264  1.0476416  -0.30634677 -1.381809    1.2759963   0.11518006\n",
            " -0.02752459 -0.09779282  0.44639724 -0.11385752  0.32669526  0.90860265\n",
            "  1.2718225  -0.04574068 -0.4660556  -0.4748065  -0.47035357 -1.2113166\n",
            " -0.0503175  -0.66095895 -1.2216059   0.41430813 -0.10100979 -0.11582404\n",
            " -0.7181584  -0.4153291   0.61402154 -0.2952637  -0.9315533   1.0790731\n",
            "  1.1305771   1.1029564   0.2265007  -0.24627751  0.5610985   0.06753017\n",
            "  0.5078384   1.2225798  -0.36962795 -0.19532877 -0.87600005 -0.26410967\n",
            " -0.23898241 -0.9134704  -0.48845714 -0.29485703  0.6705288   0.12454398\n",
            "  0.27314308 -0.03803553 -0.35497382  0.09009272  1.0678353  -1.1497115\n",
            " -1.2047358   0.20531698 -0.574085   -0.8255342   0.5190524   0.22229126\n",
            " -1.3387657   0.26658267  0.36063203  1.0328109  -0.4910492   1.5316291\n",
            "  1.757603    0.9197136  -0.51151586  0.5787309  -0.02924983  0.45303065\n",
            "  0.528781   -0.98483837 -0.9612168  -1.2670994  -0.7574611   0.31236652\n",
            " -0.27850568  1.2479885  -1.9603004  -0.09065976  1.1190438  -0.21275687\n",
            " -0.10334338  0.50072706 -0.17477566  0.31361094  0.4181163   0.03003079\n",
            "  0.05236498 -0.9498298  -0.7197059   0.04936463  0.65378714  0.964992\n",
            "  0.16954052  0.02131398 -1.2359105  -0.08825667  0.10429031  1.296867\n",
            "  0.47407237 -0.62801456  0.8017794   0.62025505  0.9860284   0.14789951\n",
            "  0.54211193 -0.722714   -0.46583515  1.0126702   0.18969229  0.7707525\n",
            " -0.8613195  -1.0796133  -0.2358519  -0.3491305   1.1298432  -0.6265288\n",
            "  0.05256244  0.16112973  0.18927719 -0.05398162 -0.3133171   0.47929284\n",
            " -0.27812037 -0.12866336 -0.4894801   0.5022217  -1.2807397   0.2558789\n",
            "  0.23638877 -1.2000707   1.0247186  -0.113152   -0.04601415 -0.12524375\n",
            "  0.21642923  0.04776008  0.4169446  -0.44749105  0.3547707  -0.8819082\n",
            " -0.24590832 -0.40024322 -0.552403   -1.2153143  -0.05229399  0.75718814\n",
            " -1.314278    0.948996   -0.22699143 -0.978167   -0.5260931   0.27384225\n",
            "  0.61793727 -0.4239601   0.08686416 -0.1634925  -0.33964714 -0.996274\n",
            " -0.4969013  -0.47678536  0.09426049  0.8673906  -0.2922783  -0.35942823\n",
            " -0.19425018 -0.500428    1.3828698   0.29197082  0.13173464  0.34909186\n",
            "  1.109577    0.1901656   0.6286086  -0.7639951  -0.37538466 -0.6906093\n",
            "  0.5247416  -0.95918    -0.13990489 -0.9999449   0.72649366 -1.1468192\n",
            " -0.39745614 -0.732104    0.94582707  0.10800126 -0.567319   -0.78492785\n",
            " -0.78907996 -0.40992385  0.24143523  0.23316582  1.5265357   1.1536835\n",
            "  1.0156866  -0.16626298  0.9263116  -0.37919068  0.08930378 -0.4222389\n",
            "  0.77592355  0.59985703  0.33405027 -0.18346214  0.70026815  0.25082913\n",
            " -0.47949177 -0.9555011  -0.15472768 -1.6383444   0.5562302  -0.81769127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZsis4V88i-",
        "colab_type": "text"
      },
      "source": [
        "# Convert each sentence into the average sum of the vector representations of its tokens\n",
        "\n",
        "Save the results into a new variable x_emb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTQktTzBdaYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO\n",
        "\n",
        "# x_emb - embedded sentences\n",
        "x_emb = np.zeros((len(x), 300))\n",
        "# Loop over sentences\n",
        "for i_snt, snt in enumerate(x):\n",
        "  cnt = 0\n",
        "  # Loop over the words of a sentence\n",
        "  for i_word, word in enumerate(snt):\n",
        "    if word in w2v.wv:\n",
        "      x_emb[i_snt] += w2v.wv.get_vector(word)\n",
        "      cnt += 1\n",
        "  if cnt > 0:\n",
        "    x_emb[i_snt] = x_emb[i_snt] / cnt\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXQJQFjdkUo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get torch stuff\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATUWE2b9VKd",
        "colab_type": "text"
      },
      "source": [
        "# Split the dataset into train/test/dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kpy4rEGnghM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "inds = np.random.permutation(len(x))\n",
        "inds_train = inds[0:int(0.8*len(x))]\n",
        "inds_test = inds[int(0.8*len(x)):int(0.9*len(x))]\n",
        "inds_dev = inds[int(0.9*len(x)):]\n",
        "\n",
        "# 80% of the dataset\n",
        "x_train = x_emb[inds_train]\n",
        "y_train = y[inds_train]\n",
        "x_train_w = np.array(x)[inds_train]\n",
        "x_train_o = np.array(x_original)[inds_train]\n",
        "\n",
        "# 10% of the dataset\n",
        "x_test = x_emb[inds_test]\n",
        "y_test = y[inds_test]\n",
        "\n",
        "# 10% of the dataset\n",
        "x_dev = x_emb[inds_dev]\n",
        "y_dev = y[inds_dev]\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "x_dev = torch.tensor(x_dev, dtype=torch.float32)\n",
        "y_dev = torch.tensor(y_dev.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZH3ssL6_dK4",
        "colab_type": "text"
      },
      "source": [
        "#Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDb8Wz0m2PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# TODO: Set the device to 'cuda'\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# TODO: Build a network with 4 layers:\n",
        "#1: 150 neurons and ReLU activation (300 inputs)\n",
        "#2: 70 neurons and ReLU activation\n",
        "#3: 25 neurons and ReLU activation\n",
        "#4: 1 neuron and sigmoid activation\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(300, 150)\n",
        "      self.fc2 = nn.Linear(150, 70)\n",
        "      self.fc3 = nn.Linear(70, 25)\n",
        "      self.fc4 = nn.Linear(25, 1)\n",
        "      \n",
        "      self.d1 = nn.Dropout(0.5)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x = self.d1(torch.relu(self.fc1(x)))\n",
        "      x = self.d1(torch.relu(self.fc2(x)))\n",
        "      x = self.d1(torch.relu(self.fc3(x)))\n",
        "      x = torch.sigmoid(self.fc4(x))\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMz8tBisAaGA",
        "colab_type": "code",
        "outputId": "0b98802a-693c-477b-aa89-02bb1e3b0237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Create the network and get BCE loss\n",
        "net = Net()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# TODO: Make a SGD optimizer with lr=0.002 and momentum=0.99\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.99)\n",
        "# TODO: Move the net to the device\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=300, out_features=150, bias=True)\n",
              "  (fc2): Linear(in_features=150, out_features=70, bias=True)\n",
              "  (fc3): Linear(in_features=70, out_features=25, bias=True)\n",
              "  (fc4): Linear(in_features=25, out_features=1, bias=True)\n",
              "  (d1): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7VRuEb9bj1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARtU1lLR_cfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move data to the right device\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "\n",
        "x_dev = x_dev.to(device)\n",
        "y_dev = y_dev.to(device)\n",
        "\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXYUTXUoS-t",
        "colab_type": "code",
        "outputId": "236c5372-23e4-4fd0-a116-bd6095da8f9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "net.train()\n",
        "losses = []\n",
        "accs = []\n",
        "accs_dev = []\n",
        "for epoch in range(10000):  # do 10,000 epochs \n",
        "  # TODO: zero the gradients on the optimizer\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # TODO: Calculate the forward pass \n",
        "  outputs = net(x_train)\n",
        "  # TODO: Calculate the loss\n",
        "  loss = criterion(outputs, y_train)\n",
        "  # TODO: Backward pass\n",
        "  loss.backward()\n",
        "  # TODO: Optimize/Update parameters\n",
        "  optimizer.step()\n",
        "  \n",
        "  # Track the changes - This is normally done using tensorboard or similar\n",
        "  losses.append(loss.item())\n",
        "  accs.append(sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs.cpu().detach().numpy()], y_train.cpu().numpy()))\n",
        "\n",
        "  # print statistics\n",
        "  if epoch % 500 == 0:\n",
        "      net.eval()\n",
        "      acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs.cpu().detach().numpy()], y_train.cpu().numpy())\n",
        "      \n",
        "      outputs_dev = net(x_dev)\n",
        "      acc_dev = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs_dev.cpu().detach().numpy()], y_dev.cpu().numpy())\n",
        "      accs_dev.append(acc_dev)\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev))\n",
        "      net.train()\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.69625 Acc: 0.502 Acc Dev: 0.484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5b0369a14b74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m# Track the changes - This is normally done using tensorboard or similar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhPQXS_uopWq",
        "colab_type": "code",
        "outputId": "ab4ed766-69d8-480a-ac99-86e8ac9deb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Switch to eval mode \n",
        "net.eval()\n",
        "net.to(device)\n",
        "print(\"Predicted value: \" + str(net(torch.tensor(x_emb[4], dtype=torch.float32).to(device))))\n",
        "print(\"Real value: \" + str(y[4]))\n",
        "print(\"Input sentence: \" + df['SentimentText'].iloc[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted value: tensor([0.4961], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "Real value: 1\n",
            "Input sentence: truly enjoyed film. acting terrific plot. Jeff Combs talent recognized for. part flick would change ending. death creature far gruesome Sci Fi Channel.<br /><br />There interesting religious messages film. Jeff Combs obviously played Messiah figure creature (or shark prefer) represented anti-Chirst. particularly frightening scenes 'end world feel'. noticed third viewing classic creature feature. know many people won't get references Christianity, watch close you'll get it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJsArQIGHz3B",
        "colab_type": "text"
      },
      "source": [
        "#Go back and add dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGjzLNow-T9_",
        "colab_type": "text"
      },
      "source": [
        "#Interpretability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2vaQdnM-Wyf",
        "colab_type": "code",
        "outputId": "ed65939e-f5f0-423e-937d-ba9fe612a070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Make a small network with one layer\n",
        "device = torch.device('cuda')\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(300, 1)\n",
        "       \n",
        "    def forward(self, x):\n",
        "      x = torch.sigmoid(self.fc1(x))\n",
        "      return x\n",
        "net = Net()\n",
        "net.to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.99)\n",
        "for epoch in range(4000):  # do 10,000 epochs \n",
        "  # zero the gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Forward \n",
        "  outputs = net(x_train)\n",
        "  # Calculate error\n",
        "  loss = criterion(outputs, y_train)\n",
        "  # Backward\n",
        "  loss.backward()\n",
        "  # Optimize/Update parameters\n",
        "  optimizer.step()\n",
        "  \n",
        "  # Track the changes - This is normally done using tensorboard or similar\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  # print statistics\n",
        "  if epoch % 500 == 0:\n",
        "      acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs.cpu().detach().numpy()], y_train.cpu().numpy())\n",
        "      \n",
        "      outputs_dev = net(x_dev)\n",
        "      acc_dev = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs_dev.cpu().detach().numpy()], y_dev.cpu().numpy())\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.69745 Acc: 0.446 Acc Dev: 0.450\n",
            "Epoch:  500 Loss: 0.44594 Acc: 0.802 Acc Dev: 0.812\n",
            "Epoch: 1000 Loss: 0.41784 Acc: 0.819 Acc Dev: 0.828\n",
            "Epoch: 1500 Loss: 0.40680 Acc: 0.824 Acc Dev: 0.832\n",
            "Epoch: 2000 Loss: 0.40068 Acc: 0.826 Acc Dev: 0.832\n",
            "Epoch: 2500 Loss: 0.39674 Acc: 0.828 Acc Dev: 0.833\n",
            "Epoch: 3000 Loss: 0.39397 Acc: 0.829 Acc Dev: 0.834\n",
            "Epoch: 3500 Loss: 0.39191 Acc: 0.829 Acc Dev: 0.838\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVx2mD7b_YZq",
        "colab_type": "code",
        "outputId": "a0af0570-d44d-49bd-d456-8d5709e98b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Print the prediction of the first 30 sentences\n",
        "for i in range(30):\n",
        "  out = net(x_train[i])\n",
        "  print(i, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor([0.3073], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "1 tensor([0.3253], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "2 tensor([0.2313], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "3 tensor([0.0269], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "4 tensor([0.0193], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "5 tensor([0.1669], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "6 tensor([0.7605], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "7 tensor([0.0024], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "8 tensor([0.0866], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "9 tensor([0.0003], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "10 tensor([0.6628], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "11 tensor([0.3097], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "12 tensor([0.9687], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "13 tensor([0.8795], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "14 tensor([0.0078], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "15 tensor([0.6120], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "16 tensor([0.0009], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "17 tensor([0.1610], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "18 tensor([0.9242], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "19 tensor([0.0486], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "20 tensor([0.4384], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "21 tensor([0.2035], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "22 tensor([0.9764], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "23 tensor([0.3484], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "24 tensor([0.4589], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "25 tensor([0.9520], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "26 tensor([0.9832], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "27 tensor([0.0229], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "28 tensor([0.9796], device='cuda:0', grad_fn=<SigmoidBackward>)\n",
            "29 tensor([0.9551], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCVkmeCE_iKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the 'i_snt' to high prob\n",
        "i_snt = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeAWnVvA-r4h",
        "colab_type": "code",
        "outputId": "050ad528-5c4e-4ff3-8002-fbba2d0944f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "prod = []\n",
        "# Take the weights of our layer\n",
        "we = net.fc1.weight.detach().cpu().numpy()[0]\n",
        "# For each word in the dataset check how much did it contribute to the \n",
        "#final classification\n",
        "for ind, word in enumerate(x_train_w[i_snt]):\n",
        "  if word in w2v:\n",
        "    prod.append(np.dot(we, w2v.wv.get_vector(word)))\n",
        "  else:\n",
        "    prod.append(0)\n",
        "    \n",
        "# Sort the contributions\n",
        "srt = np.argsort(prod)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mewfla3Q_Gfi",
        "colab_type": "code",
        "outputId": "603d2468-0d5c-4902-e6a3-3d9b5a1a034a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "print(x_train_o[i_snt].replace(\"<br /><br />\", \"\\n\"))\n",
        "print()\n",
        "# print the top 10 words that contributed the most\n",
        "for i in range(1, 30):\n",
        "  print(x_train_w[i_snt][srt[-i]], prod[srt[-i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1954 Marlon Brando hot actor performances Streetcar Named Desire Waterfront. Frank Sinatra yet re-invent silver screen. Sinatra's portrayal erstwhile Nathan Detroit, helped re-establish Sinatra fans.\n",
            "It great screen version great play choices leads support players terrific. Imagine movie Brando sings? one singing role portrayed Sky Masterson. addition female leads, Jean Simmons Vivian Blaine(replaying stage role Nathan's long suffering girlfriend Adelade), put superlative efforts. Special mention goes great Stubby Kaye(as Nicely Nicely), due respect Eric Clapton, one's version Rockin' Boat even comes close Stubby's. Sheldon Leonard, would go fame TV producer shows Danny Thomas Show Dick Van Dyke Show \"Harry Horse\" wonders, B.S.Pulley excellent harsh mannered rough talking \"Big Julie\", even Regis Toomey offers excellence \"Brother Arvide\".\n",
            "It one fun musicals see, good comedy, get Sinatra Brando. Soooooo \"Luck Lady Tonight\" brother...\"it's dice\"\n",
            "\n",
            "great 33.542725\n",
            "great 33.542725\n",
            "great 33.542725\n",
            "excellent 29.185163\n",
            "fan 17.848677\n",
            "fun 17.56714\n",
            "support 15.946435\n",
            "musical 13.891341\n",
            "comedy 13.824916\n",
            "good 13.692469\n",
            "terrific 13.47831\n",
            "performance 11.476732\n",
            "frank 11.449275\n",
            "show 10.89473\n",
            "sky 10.6551\n",
            "sing 9.752717\n",
            "harry 9.291575\n",
            "close 9.25266\n",
            "portrayal 8.263994\n",
            "sinatra 8.128684\n",
            "sinatra 8.128684\n",
            "sinatra 8.128684\n",
            "sinatra 8.128684\n",
            "fame 6.7891064\n",
            "singing 6.740686\n",
            "nicely 6.708851\n",
            "nicely 6.708851\n",
            "player 6.684932\n",
            "danny 6.4746246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoAXnTuhAenx",
        "colab_type": "code",
        "outputId": "27aa3a8d-eef9-404d-dcd9-c4584a2843bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#TODO: Write a movie review - at least 20 words\n",
        "review = \"That was a bad movie, the acting was outstanding and very nicely done\"\n",
        "print(review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "That was a bad movie, the acting was outstanding and very nicely done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TemK6Xj4GlbF",
        "colab_type": "code",
        "outputId": "bb1f7c4b-25c4-41c6-fd9b-c7bd6cb5673e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO: Tokenize the review using spacy - same as we have done above\n",
        "tkns = [tkn.lemma_.lower() for tkn in nlp(review) if not tkn.is_punct and not tkn.is_stop]\n",
        "print(tkns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bad', 'movie', 'acting', 'outstanding', 'nicely']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhH-GngNCqwz",
        "colab_type": "code",
        "outputId": "e6d527f8-1c7e-4487-87ac-7fe2b153d114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# TODO: Convert the tokens to vectors and save into an array\n",
        "vecs = [w2v.wv.get_vector(t) for t in tkns]\n",
        "print(vecs[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.20606323  1.3679227   0.6210256  -1.8426057   1.0910314   0.49461135\n",
            " -0.35775855 -1.3945628  -0.19248852 -0.3548711   0.0883837  -0.42080787\n",
            " -0.06015233  0.5568484  -1.1982398  -0.962829   -0.49825323 -0.790805\n",
            " -1.0691336  -0.6467634  -0.3542181   1.1681327   0.78733665  0.11711236\n",
            "  0.8981934  -1.0393045  -0.22445396  0.7769544   0.44682854  0.36421224\n",
            " -0.7480011   0.79511076 -0.1325793  -0.29321134  0.8712999   0.7578471\n",
            "  0.31934336 -0.13637286  0.62699115  0.49465156  0.42198205  0.16660051\n",
            " -0.31003457  0.735745    0.02922532 -0.0129219  -1.1790099   0.00681409\n",
            " -0.7079715   0.18703519  0.28941944  0.21530084 -0.10562854  0.85863453\n",
            " -0.52595544 -0.10525871  0.25151446 -0.18472372  0.85094064 -1.314031\n",
            " -0.07612921  0.2842826   0.09997708 -1.0896975   0.37234488  0.48612958\n",
            "  0.23525228  0.82082206 -0.73600215  0.9584411   0.90113777 -0.22174488\n",
            " -0.00359149  0.09651064  0.23238002  0.44414145 -0.50571036  0.59870267\n",
            "  1.1984115  -0.24825507  0.81835485 -0.57639414 -0.49300018 -0.74173814\n",
            " -0.09765264  1.0476416  -0.30634677 -1.381809    1.2759963   0.11518006\n",
            " -0.02752459 -0.09779282  0.44639724 -0.11385752  0.32669526  0.90860265\n",
            "  1.2718225  -0.04574068 -0.4660556  -0.4748065  -0.47035357 -1.2113166\n",
            " -0.0503175  -0.66095895 -1.2216059   0.41430813 -0.10100979 -0.11582404\n",
            " -0.7181584  -0.4153291   0.61402154 -0.2952637  -0.9315533   1.0790731\n",
            "  1.1305771   1.1029564   0.2265007  -0.24627751  0.5610985   0.06753017\n",
            "  0.5078384   1.2225798  -0.36962795 -0.19532877 -0.87600005 -0.26410967\n",
            " -0.23898241 -0.9134704  -0.48845714 -0.29485703  0.6705288   0.12454398\n",
            "  0.27314308 -0.03803553 -0.35497382  0.09009272  1.0678353  -1.1497115\n",
            " -1.2047358   0.20531698 -0.574085   -0.8255342   0.5190524   0.22229126\n",
            " -1.3387657   0.26658267  0.36063203  1.0328109  -0.4910492   1.5316291\n",
            "  1.757603    0.9197136  -0.51151586  0.5787309  -0.02924983  0.45303065\n",
            "  0.528781   -0.98483837 -0.9612168  -1.2670994  -0.7574611   0.31236652\n",
            " -0.27850568  1.2479885  -1.9603004  -0.09065976  1.1190438  -0.21275687\n",
            " -0.10334338  0.50072706 -0.17477566  0.31361094  0.4181163   0.03003079\n",
            "  0.05236498 -0.9498298  -0.7197059   0.04936463  0.65378714  0.964992\n",
            "  0.16954052  0.02131398 -1.2359105  -0.08825667  0.10429031  1.296867\n",
            "  0.47407237 -0.62801456  0.8017794   0.62025505  0.9860284   0.14789951\n",
            "  0.54211193 -0.722714   -0.46583515  1.0126702   0.18969229  0.7707525\n",
            " -0.8613195  -1.0796133  -0.2358519  -0.3491305   1.1298432  -0.6265288\n",
            "  0.05256244  0.16112973  0.18927719 -0.05398162 -0.3133171   0.47929284\n",
            " -0.27812037 -0.12866336 -0.4894801   0.5022217  -1.2807397   0.2558789\n",
            "  0.23638877 -1.2000707   1.0247186  -0.113152   -0.04601415 -0.12524375\n",
            "  0.21642923  0.04776008  0.4169446  -0.44749105  0.3547707  -0.8819082\n",
            " -0.24590832 -0.40024322 -0.552403   -1.2153143  -0.05229399  0.75718814\n",
            " -1.314278    0.948996   -0.22699143 -0.978167   -0.5260931   0.27384225\n",
            "  0.61793727 -0.4239601   0.08686416 -0.1634925  -0.33964714 -0.996274\n",
            " -0.4969013  -0.47678536  0.09426049  0.8673906  -0.2922783  -0.35942823\n",
            " -0.19425018 -0.500428    1.3828698   0.29197082  0.13173464  0.34909186\n",
            "  1.109577    0.1901656   0.6286086  -0.7639951  -0.37538466 -0.6906093\n",
            "  0.5247416  -0.95918    -0.13990489 -0.9999449   0.72649366 -1.1468192\n",
            " -0.39745614 -0.732104    0.94582707  0.10800126 -0.567319   -0.78492785\n",
            " -0.78907996 -0.40992385  0.24143523  0.23316582  1.5265357   1.1536835\n",
            "  1.0156866  -0.16626298  0.9263116  -0.37919068  0.08930378 -0.4222389\n",
            "  0.77592355  0.59985703  0.33405027 -0.18346214  0.70026815  0.25082913\n",
            " -0.47949177 -0.9555011  -0.15472768 -1.6383444   0.5562302  -0.81769127]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSocSg4SGugV",
        "colab_type": "code",
        "outputId": "0563cc17-3937-40dd-b863-aef5b6835d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "# TODO: Average the vectors and convert to torch tensor\n",
        "emb = torch.tensor(np.average(vecs, axis=0)).to(device)\n",
        "print(emb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.0881,  0.3245, -0.1197, -0.9365,  0.3300,  0.0125, -0.2991, -0.5606,\n",
            "        -0.2704,  0.2961,  0.0647, -0.2851, -0.2340,  0.3680, -0.3864, -0.3927,\n",
            "        -0.0117, -0.0193, -0.5287, -0.1701, -0.1592,  0.6323,  0.1107,  0.4675,\n",
            "         0.0104, -0.4616, -0.3450, -0.3582,  0.0851,  0.2080, -0.2619,  0.0538,\n",
            "        -0.3042,  0.3085,  0.0194,  0.3483,  0.3487, -0.3948, -0.0271,  0.7158,\n",
            "         0.0517, -0.3013, -0.0306,  0.3832,  0.0191, -0.1180, -0.5050,  0.2895,\n",
            "        -0.4173, -0.0829, -0.0809,  0.0196,  0.2391,  0.5764, -0.0121,  0.4341,\n",
            "         0.4631,  0.0866,  0.3537, -0.6668, -0.0789, -0.1183, -0.1913, -0.4304,\n",
            "         0.5567,  0.3633,  0.4758, -0.0018,  0.1379,  0.5448,  0.5732, -0.2979,\n",
            "        -0.0656,  0.0569, -0.2395, -0.1267, -0.6942,  0.1206,  1.0651, -0.5760,\n",
            "         0.2579, -0.1882, -0.2617, -0.3479,  0.4230,  0.2156,  0.0906, -0.5406,\n",
            "         0.3603, -0.0405, -0.5859,  0.2975,  0.8231,  0.0034,  0.5140,  0.1360,\n",
            "         0.7230,  0.0605, -0.4325, -0.1576, -0.1445, -0.5283, -0.0877, -0.4005,\n",
            "        -0.1273,  0.3560,  0.0440,  0.1300, -0.2445,  0.0723,  0.0978, -0.1942,\n",
            "        -0.1726,  0.0636,  0.5267,  0.0549, -0.3429,  0.7656, -0.1711,  0.2239,\n",
            "        -0.2042,  0.2881, -0.2032, -0.0398, -0.0630, -0.5219, -0.1514, -0.4006,\n",
            "         0.0931, -0.0388,  0.5189,  0.0520,  0.5127, -0.3112, -0.3197,  0.7257,\n",
            "         0.7227, -0.0079, -0.2685,  0.1602, -0.3163, -0.1780,  0.2360, -0.0593,\n",
            "        -0.6412,  0.3217, -0.0798,  0.5140, -0.4647,  0.3943,  0.7518,  0.0116,\n",
            "         0.3678,  0.4793, -0.0443,  0.2287,  0.0562, -0.1406,  0.0478, -0.7830,\n",
            "        -0.5932,  0.4344, -0.3848,  0.6090, -0.6729,  0.0219,  0.6451, -0.3864,\n",
            "         0.0624, -0.0850, -0.0022, -0.0634, -0.1209, -0.1537,  0.2515,  0.0212,\n",
            "        -0.0764,  0.2319, -0.1083,  0.8137,  0.5804, -0.0498, -0.0917, -0.1143,\n",
            "        -0.0860,  0.6383,  0.7450, -0.4366,  0.0724,  0.3100,  0.9594,  0.4334,\n",
            "         0.1262, -0.4475, -0.1146,  0.8965,  0.1293,  0.3200, -0.1109, -0.5450,\n",
            "        -0.0865,  0.4532,  0.5027, -0.6910,  0.4808,  0.1352, -0.2632, -0.3028,\n",
            "         0.3347, -0.0613, -0.7199,  0.0687,  0.2286,  0.5183, -0.5701,  0.0364,\n",
            "        -0.0142, -0.4224,  0.4971,  0.2905,  0.0780,  0.2040, -0.3951,  0.1752,\n",
            "         0.2350, -0.0811,  0.1474, -0.3753, -0.5171, -0.0982, -0.3172, -0.4701,\n",
            "        -0.3610,  0.4309, -0.5413,  0.3133, -0.6796, -0.3441,  0.0577,  0.2655,\n",
            "         0.3042, -0.3670,  0.0051, -0.0997, -0.2798, -0.7547, -0.4068, -0.1166,\n",
            "         0.0770,  0.5319, -0.1999, -0.0699, -0.3075, -0.4380,  0.6747, -0.0460,\n",
            "        -0.1142, -0.1089,  0.2947,  0.4757,  0.1935, -0.3460,  0.1250, -0.3417,\n",
            "         0.7247, -0.2976, -0.1890, -0.5555,  0.5302, -0.4217, -0.2825, -0.7124,\n",
            "         0.5550, -0.1514,  0.3032, -0.6716, -0.3787,  0.0551,  0.2872,  0.1620,\n",
            "         0.2890,  0.3526,  0.5971,  0.2862,  0.3051,  0.2283,  0.2851, -0.5660,\n",
            "         0.0231,  0.3617, -0.0690,  0.1311,  0.0834,  0.2154,  0.3706, -0.4802,\n",
            "        -0.3021, -0.7005,  0.3052, -0.3215], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWwz_6vqC6ZD",
        "colab_type": "code",
        "outputId": "5a5038b0-493c-4309-cb72-7853269eefc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO: Calculate the output for our review\n",
        "net(emb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0015], device='cuda:0', grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APusGyPaC9V1",
        "colab_type": "code",
        "outputId": "d9203a19-3464-48ec-9292-4d10e0494102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# TODO: Multiply the vector representations of tokens by 'we' and print \n",
        "#contribution of each word\n",
        "for ind, vec in enumerate(vecs):\n",
        "  print(tkns[ind], np.dot(vec, we))    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bad -30.532072\n",
            "movie 0.7983703\n",
            "acting -20.092594\n",
            "outstanding 12.827596\n",
            "nicely 6.708851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAzHbYi2NrHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}