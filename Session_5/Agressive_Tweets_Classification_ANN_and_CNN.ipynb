{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agressive Tweets Classification - ANN and CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxzowbvjr6dt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "BEfore doing anything **Switch to GPU**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gMRbn0Zvsm6",
        "colab_type": "text"
      },
      "source": [
        "# Prepare your environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWCYuCdSrHao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORTS (try to organize/group your imports)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "from os import path\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, \\\n",
        "                            recall_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjxy_DO1VVBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Any global variables\n",
        "SEED = 15\n",
        "DATA_PATH = '/content/'\n",
        "MAX_SEQ_LEN = 40\n",
        "nlp = spacy.load('en')\n",
        "DEVICE = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FCp4JKKsduN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set SEEDs\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIgXsF_6vnLs",
        "colab_type": "text"
      },
      "source": [
        "# Examine and Prepare the Data\n",
        "\n",
        "\n",
        "## In deep learning it is not very often that we load the whole dataset into memory, especially the text portion of datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3nWZJtv4bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download the data and save into raw_data.txt\n",
        "import requests\n",
        "url = \"https://raw.githubusercontent.com/w-is-h/DeepLearningNLP-Medical/master/Session_5/data/tweets.json\"\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "# Save the dataset into a file\n",
        "f_raw_data = open(path.join(DATA_PATH, 'raw_data.txt'), 'wb')\n",
        "f_raw_data.write(response.content)\n",
        "f_raw_data.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4_rWM75Wp7W",
        "colab_type": "code",
        "outputId": "91debc74-a4ff-4b45-b6b3-59706cb7d889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# To checkout files we now use bash commands\n",
        "!head /content/raw_data.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"content\": \"Get fucking real dude.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"Dude they dont finish enclosing the fucking showers. I hate half assed jobs. Whats the reasononing behind it? Makes no sense.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"WTF are you talking about Men? No men thats not a menage  that's just gay.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"Ill save you the trouble sister. Here comes a big ol fuck France block coming your way here on the twitter.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"Im dead serious.Real athletes never cheat don't even have the appearance of at his level. Fuck him dude seriously  I think he did\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"...go absolutely insane.hate to be the bearer of bad news..LoL..dont shoot the messenger (cause we all know you bought that pistol\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"Lmao  im watching the same thing ahaha. The gay guy is hilarious! \\\"Dede having a good day and I dont want anyone to mess it up.\\\"\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n",
            "{\"content\": \"LOL  no he said  What do you call a jail cell to a gay guy? Paradise! ahaha.\",\"annotation\":{\"notes\":\"\",\"label\":[\"1\"]},\"extras\":null,\"metadata\":{\"first_done_at\":1527503426000,\"last_updated_at\":1527503426000,\"sec_taken\":0,\"last_updated_by\":\"jI67aE5hwwdh6l16bcfFVnpyREd2\",\"status\":\"done\",\"evaluation\":\"NONE\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5WXv-mY0A5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f_x_raw = open(path.join(DATA_PATH, 'x_raw.txt'), 'w')\n",
        "# We load labels because they are small\n",
        "y = []\n",
        "\n",
        "\n",
        "for line in open(path.join(DATA_PATH, 'raw_data.txt'), 'rb'):\n",
        "  # Each line is in fact a json document\n",
        "  doc = json.loads(line) \n",
        "\n",
        "  # TODO: Write text to the file and append labels to 'y',\n",
        "  #each row must contain the text of one tweet\n",
        "  f_x_raw.write(\"{}\\n\".format(doc['content']))\n",
        "  y.append(int(doc['annotation']['label'][0]))\n",
        "\n",
        "# Close the file\n",
        "f_x_raw.close()\n",
        "\n",
        "# This is a typical way to add sanity checks to your code, can be very helpful.\n",
        "assert type(y[0]) == int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO_6oD_xgOHz",
        "colab_type": "text"
      },
      "source": [
        "### Before cleaning we should analyse the dataset and understand what to remove or keep, but I've already done that so we skip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax8Lrwvv3yt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Cleaning\n",
        "# Every time a character (excluding numbers) is repeated more than 2 times, \n",
        "# reduce to 2 - e.g. \"0000 yesssssssss!!!!!!\" -> \"0000 yess!!\"\n",
        "def clean_text(text):\n",
        "  clean_text = re.sub(r'([^0-9]{1})\\1{2,}', r'\\1\\1', text)\n",
        "  return clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjYEC4kB0s63",
        "colab_type": "code",
        "outputId": "c0b1eaa7-e811-4dd0-9fd0-ace49e6a7d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test the clean_text function\n",
        "test_text = \"0000 yesssssss!!!!!!\"\n",
        "test_out = clean_text(test_text)\n",
        "print(test_out)\n",
        "\n",
        "real_out = \"0000 yess!!\"\n",
        "assert real_out == test_out"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0000 yess!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAo39Tb74u-",
        "colab_type": "text"
      },
      "source": [
        "# Download Word Embeddings\n",
        "\n",
        "It is very rare to train your own embeddings, if your domain is not exteremly specific. Usually we use pretrained embeddings.\n",
        "\n",
        "In this case we are going to use embeddings from GloVe: Global Vectors for Word Representation. They have pretrained vectors for twitter datasets. \n",
        "\n",
        "\n",
        "**NOTE:**\n",
        "\n",
        "The downside of doing this is that we can't continue the trainig of the vectors unless they are in the gensim word2vec format. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "More info at: https://nlp.stanford.edu/projects/glove/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syTY4srd-kJh",
        "colab_type": "code",
        "outputId": "9a1f24ed-9f4f-49af-fad2-3c2228f9d691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# JUPYTER/COLAB ONLY!!!\n",
        "# Download the data\n",
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-09 23:39:40--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-09-09 23:39:40--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2019-09-09 23:39:40--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip.3’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  36.9MB/s    in 42s     \n",
            "\n",
            "2019-09-09 23:40:23 (34.1 MB/s) - ‘glove.twitter.27B.zip.3’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "replace glove.twitter.27B.25d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er4vmxdi_eLe",
        "colab_type": "code",
        "outputId": "d4c1f6a7-3460-4334-8c75-572f338a780c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Load the vectors\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "# Convert glove file to word2vec format\n",
        "glove_file = datapath('/content/glove.twitter.27B.200d.txt')\n",
        "tmp_file = get_tmpfile(\"tmp_word2vec.txt\")\n",
        "_ = glove2word2vec(glove_file, tmp_file)\n",
        "\n",
        "# Load the newly generated file\n",
        "model = KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiESc4WsDpBp",
        "colab_type": "code",
        "outputId": "f1916abb-7bb5-43d6-e38c-12fb35bcd1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Sanity - Check similarity \n",
        "model.most_similar(\"house\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('room', 0.799299418926239),\n",
              " ('home', 0.7727779746055603),\n",
              " ('apartment', 0.7143650054931641),\n",
              " ('party', 0.7122235894203186),\n",
              " ('out', 0.6893113255500793),\n",
              " ('my', 0.683701753616333),\n",
              " ('dad', 0.680922269821167),\n",
              " (\"'s\", 0.6800175309181213),\n",
              " ('going', 0.6792358756065369),\n",
              " ('up', 0.6730260848999023)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av6z5kuuBmXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = [] # A list of embeddings for each word in the word2vec vocab\n",
        "\n",
        "# Embeddings is a list, meaning we know that embeddings[1] is a vector for the \n",
        "#word with ID=1, but we don't know what word is that. That is why we need \n",
        "#the id2word and word2id mappings.\n",
        "id2word = {}\n",
        "word2id = {}\n",
        "\n",
        "# Loop over all words in the vocabulary and add the values\n",
        "for word in model.vocab.keys():\n",
        "  id2word[len(embeddings)] = word\n",
        "  word2id[word] = len(embeddings)\n",
        "  embeddings.append(model[word])\n",
        "\n",
        "# Add <UNK> and <PAD>\n",
        "word = \"<UNK>\"\n",
        "id2word[len(embeddings)] = word\n",
        "word2id[word] = len(embeddings)\n",
        "embeddings.append(np.random.rand(len(embeddings[0])))\n",
        "word = \"<PAD>\"\n",
        "id2word[len(embeddings)] = word\n",
        "word2id[word] = len(embeddings)\n",
        "embeddings.append(np.zeros(len(embeddings[0])))\n",
        "\n",
        "# TODO: Convert the embeddings list into a numpy array\n",
        "#embeddings = 0#?\n",
        "\n",
        "# Convert the embeddings list into a tensor\n",
        "embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
        "\n",
        "# Sanity\n",
        "assert len(embeddings) == len(id2word) == len(word2id)\n",
        "assert model['house'][0] == embeddings[word2id['house']][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXbEK9VOFtkG",
        "colab_type": "text"
      },
      "source": [
        "# Convert words to integers\n",
        "\n",
        "Usually we don't want to keep our input in the string format, it is very time/memory costly to load text all the time. We want to convert text into integers. That is why we have our mapping `word2id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fumksoMuGDFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ind = []\n",
        "for text in open(path.join(DATA_PATH, 'x_raw.txt')):\n",
        "  # TODO: clean text\n",
        "  text = clean_text(text.strip())\n",
        "  # Covnert text to lowercased tokens, skip punct and white-space\n",
        "  tkns = [tkn.lower_ for tkn in nlp.tokenizer(text) if not tkn.is_punct and\n",
        "          len(tkn.lower_.strip()) > 0]\n",
        "  # Convert each token into its id\n",
        "  ind_tkns = [word2id.get(tkn, word2id.get(\"<UNK>\")) for tkn in tkns]\n",
        "  # Append to x_ind\n",
        "  x_ind.append(ind_tkns)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlEwkAh8VTyU",
        "colab_type": "code",
        "outputId": "92ad815a-fd70-4f32-a2fe-c5e17089e3d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x_ind[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[147, 32, 124, 2567, 124, 109, 243, 26, 45, 80773, 1193514, 13, 25700, 70, 55, 408, 22480, 33, 41, 11, 1697, 183, 15927, 273, 63]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5eSfp4c_f2",
        "colab_type": "code",
        "outputId": "7e9f430d-dbfe-4d69-84e5-242878f522bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO: convert the indexes for x_ind[1] back to words\n",
        "\" \".join([id2word[i] for i in x_ind[1]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"she is as dirty as they come and that crook <UNK> the dems are so fucking corrupt it 's a joke make republicans look like\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_tr32vkdH94",
        "colab_type": "text"
      },
      "source": [
        "# Analyse the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhKFnOtrhKwc",
        "colab_type": "code",
        "outputId": "a0d40eca-41e8-494b-a25c-48cd6f8e5580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# TODO: For each tweet calculate its length and add to tweet_lengths, plus \n",
        "#calculate all the statistics\n",
        "tweet_lengths = [len(tweet) for tweet in x_ind]\n",
        "pos = np.sum(y) # Number of positive examples\n",
        "neg = len(y) - pos # Number of negative examples \n",
        "avg = np.average(tweet_lengths) # Average tweet length\n",
        "md = np.median(tweet_lengths) # Median tweet length\n",
        "mx = np.max(tweet_lengths) # Maximum tweet length\n",
        "mi = np.min(tweet_lengths) # Minimum tweet length\n",
        "\n",
        "print(\"Number of positive examples: {}\".format(neg))\n",
        "print(\"Number of negative examples: {}\".format(pos))\n",
        "print(\"Average length of the tweets: {}\".format(avg))\n",
        "print(\"Median length of the tweets: {}\".format(md))\n",
        "print(\"Max length of the tweets: {}\".format(mx))\n",
        "print(\"Min length of the tweets: {}\".format(mi))\n",
        "\n",
        "prim_tweet_lens = np.array([ln if ln > 0 else 1 for ln in tweet_lengths])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive examples: 12179\n",
            "Number of negative examples: 7822\n",
            "Average length of the tweets: 13.369781510924454\n",
            "Median length of the tweets: 12.0\n",
            "Max length of the tweets: 363\n",
            "Min length of the tweets: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-SqG_957EiR",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfAKFrxZkP8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad everything to the same length, or remove the extra\n",
        "x_ind_pad = []\n",
        "for i in range(len(x_ind)):\n",
        "  tweet = x_ind[i]\n",
        "  tweet = tweet[0:MAX_SEQ_LEN]\n",
        "  if len(tweet) < MAX_SEQ_LEN:\n",
        "    tweet.extend([word2id['<PAD>']] * (MAX_SEQ_LEN - len(tweet)))\n",
        "  x_ind_pad.append(tweet)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2TlgfGpbTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_lengths = [len(tweet) for tweet in x_ind_pad]\n",
        "# TODO: Print again the stats from above\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_PU9YGjo-Ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split into train/test and move to pytorch \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test, l_train, l_test = train_test_split(x_ind_pad, y, prim_tweet_lens, test_size=0.2, random_state=SEED)\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "l_train = torch.tensor(l_train, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "l_test = torch.tensor(l_test, dtype=torch.float32).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9U-7uYTCQnl",
        "colab_type": "text"
      },
      "source": [
        "# Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtJdSi1Xplft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, embeddings):\n",
        "    super(Net, self).__init__()\n",
        "    # Get the required sizes\n",
        "    vocab_size = len(embeddings)\n",
        "    embedding_size = len(embeddings[0])\n",
        "    # Initialize embeddings\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.embeddings.load_state_dict({'weight': embeddings})\n",
        "    # Disable training for the embeddings - IMPORTANT\n",
        "    self.embeddings.weight.requires_grad = False\n",
        "\n",
        "    # TODO add three layers, \n",
        "    # 1) 200 neurons \n",
        "    # 2) 50 neurons \n",
        "    # 3) 2 neurons\n",
        "    self.fc1 = nn.Linear(embedding_size, 200)\n",
        "    self.fc2 = nn.Linear(200, 50)\n",
        "    self.fc3 = nn.Linear(50, 2)\n",
        "\n",
        "    # TODO: create one dropout layer with p=0.5\n",
        "    self.d1 = nn.Dropout(0.5)\n",
        "\n",
        "  def forward(self, x, lns):\n",
        "    # Embed the input: from id -> vec\n",
        "    x = self.embeddings(x)\n",
        "    \n",
        "    # We did not average the words per sentence until now, we'll\n",
        "    #do it here\n",
        "    x = torch.sum(x, dim=1) \n",
        "    x = x / lns\n",
        "\n",
        "    # TODO: run 'x' through the layers, add dropout to the first and second\n",
        "    x = self.d1(torch.relu(self.fc1(x)))\n",
        "    x = self.d1(torch.relu(self.fc2(x)))\n",
        "    x = torch.sigmoid(self.fc3(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEzGZJfm-RTF",
        "colab_type": "code",
        "outputId": "2b8be3c3-2b99-4277-ec1c-f89d581b3a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Device\n",
        "device = torch.device(DEVICE)\n",
        "# Create the network and get CE loss\n",
        "net = Net(embeddings)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Make a SGD optimizer with lr=0.002 and momentum=0.99\n",
        "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "print(parameters)\n",
        "optimizer = optim.SGD(parameters, lr=0.01, momentum=0.99)\n",
        "# Move the net to the device\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<filter object at 0x7fa6a6d5e748>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embeddings): Embedding(1193516, 200)\n",
              "  (fc1): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
              "  (d1): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D23v2YfGCWs3",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB9j6GSkCFeC",
        "colab_type": "code",
        "outputId": "cf421be8-5140-40cd-a751-8a2918a3d5e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "device = torch.device(DEVICE)\n",
        "# Move data to the right device only test, train is in batches\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "l_test = l_test.to(device)\n",
        "\n",
        "losses = []\n",
        "accs = []\n",
        "accs_dev = []\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "# TODO: calculate the number of batches given training size len(x_train)\n",
        "num_batches = int(np.ceil(len(x_train) / batch_size))\n",
        "for epoch in range(200):\n",
        "  # TODO: Switch network to train mode\n",
        "  net.train()\n",
        "\n",
        "  # Create the running loss array\n",
        "  running_loss = []\n",
        "  for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = (i+1) * batch_size\n",
        "    \n",
        "    # TODO: Get the batch\n",
        "    x_train_batch = x_train[start:end] #?\n",
        "    y_train_batch = y_train[start:end] #?  \n",
        "    l_train_batch = l_train[start:end] #? \n",
        "\n",
        "    # TODO: Move the batches to the right device\n",
        "    x_train_batch = x_train_batch.to(device) #?\n",
        "    y_train_batch = y_train_batch.to(device) #?\n",
        "    l_train_batch = l_train_batch.to(device) #?\n",
        "\n",
        "    # TODO: zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Get outputs for our batch\n",
        "    outputs = net(x_train_batch, l_train_batch)\n",
        "    # Get loss\n",
        "    loss = criterion(outputs, y_train_batch)\n",
        "    # Do the backward step\n",
        "    loss.backward()\n",
        "    # Do the optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Add the loss to the running_loss\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "      net.eval()\n",
        "      outputs = net(x_train_batch, l_train_batch)\n",
        "      acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in torch.max(outputs, 1)[1].cpu().detach().numpy()], y_train_batch.cpu().numpy())\n",
        "\n",
        "      outputs_dev = net(x_test, l_test)\n",
        "      acc_dev = sklearn.metrics.accuracy_score(torch.max(outputs_dev, 1)[1].cpu().detach().numpy(), y_test.cpu().numpy())\n",
        "      f1_dev = f1_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      p_dev = precision_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      r_dev = recall_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f} F1 Dev: {:.3f} p Dev: {:.3f} r Dev: {:.3f}\".format(epoch, np.average(running_loss), acc, acc_dev, f1_dev, p_dev, r_dev))\n",
        "      \n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.68610 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:    5 Loss: 0.67386 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:   10 Loss: 0.66785 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:   15 Loss: 0.66392 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:   20 Loss: 0.65122 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:   25 Loss: 0.62890 Acc: 0.608 Acc Dev: 0.616 F1 Dev: 0.000 p Dev: 0.000 r Dev: 0.000\n",
            "Epoch:   30 Loss: 0.60465 Acc: 0.663 Acc Dev: 0.696 F1 Dev: 0.559 p Dev: 0.631 r Dev: 0.501\n",
            "Epoch:   35 Loss: 0.59050 Acc: 0.684 Acc Dev: 0.707 F1 Dev: 0.593 p Dev: 0.636 r Dev: 0.555\n",
            "Epoch:   40 Loss: 0.58073 Acc: 0.688 Acc Dev: 0.707 F1 Dev: 0.590 p Dev: 0.638 r Dev: 0.549\n",
            "Epoch:   45 Loss: 0.57594 Acc: 0.702 Acc Dev: 0.718 F1 Dev: 0.610 p Dev: 0.650 r Dev: 0.573\n",
            "Epoch:   50 Loss: 0.57137 Acc: 0.719 Acc Dev: 0.715 F1 Dev: 0.615 p Dev: 0.639 r Dev: 0.593\n",
            "Epoch:   55 Loss: 0.57187 Acc: 0.714 Acc Dev: 0.720 F1 Dev: 0.581 p Dev: 0.684 r Dev: 0.506\n",
            "Epoch:   60 Loss: 0.56814 Acc: 0.725 Acc Dev: 0.724 F1 Dev: 0.608 p Dev: 0.670 r Dev: 0.557\n",
            "Epoch:   65 Loss: 0.56473 Acc: 0.715 Acc Dev: 0.725 F1 Dev: 0.578 p Dev: 0.705 r Dev: 0.490\n",
            "Epoch:   70 Loss: 0.56681 Acc: 0.727 Acc Dev: 0.727 F1 Dev: 0.584 p Dev: 0.705 r Dev: 0.499\n",
            "Epoch:   75 Loss: 0.56921 Acc: 0.711 Acc Dev: 0.713 F1 Dev: 0.518 p Dev: 0.729 r Dev: 0.402\n",
            "Epoch:   80 Loss: 0.56608 Acc: 0.724 Acc Dev: 0.721 F1 Dev: 0.569 p Dev: 0.701 r Dev: 0.479\n",
            "Epoch:   85 Loss: 0.56969 Acc: 0.726 Acc Dev: 0.728 F1 Dev: 0.581 p Dev: 0.713 r Dev: 0.490\n",
            "Epoch:   90 Loss: 0.56178 Acc: 0.742 Acc Dev: 0.726 F1 Dev: 0.605 p Dev: 0.680 r Dev: 0.545\n",
            "Epoch:   95 Loss: 0.56327 Acc: 0.733 Acc Dev: 0.722 F1 Dev: 0.613 p Dev: 0.660 r Dev: 0.572\n",
            "Epoch:  100 Loss: 0.55945 Acc: 0.742 Acc Dev: 0.726 F1 Dev: 0.594 p Dev: 0.689 r Dev: 0.522\n",
            "Epoch:  105 Loss: 0.55602 Acc: 0.736 Acc Dev: 0.731 F1 Dev: 0.612 p Dev: 0.687 r Dev: 0.551\n",
            "Epoch:  110 Loss: 0.56172 Acc: 0.727 Acc Dev: 0.724 F1 Dev: 0.582 p Dev: 0.697 r Dev: 0.499\n",
            "Epoch:  115 Loss: 0.56201 Acc: 0.737 Acc Dev: 0.724 F1 Dev: 0.604 p Dev: 0.674 r Dev: 0.547\n",
            "Epoch:  120 Loss: 0.55784 Acc: 0.744 Acc Dev: 0.727 F1 Dev: 0.590 p Dev: 0.697 r Dev: 0.512\n",
            "Epoch:  125 Loss: 0.55829 Acc: 0.734 Acc Dev: 0.725 F1 Dev: 0.586 p Dev: 0.695 r Dev: 0.507\n",
            "Epoch:  130 Loss: 0.56225 Acc: 0.743 Acc Dev: 0.728 F1 Dev: 0.602 p Dev: 0.689 r Dev: 0.535\n",
            "Epoch:  135 Loss: 0.56678 Acc: 0.733 Acc Dev: 0.723 F1 Dev: 0.570 p Dev: 0.705 r Dev: 0.478\n",
            "Epoch:  140 Loss: 0.56650 Acc: 0.738 Acc Dev: 0.725 F1 Dev: 0.607 p Dev: 0.672 r Dev: 0.554\n",
            "Epoch:  145 Loss: 0.56120 Acc: 0.723 Acc Dev: 0.722 F1 Dev: 0.573 p Dev: 0.699 r Dev: 0.486\n",
            "Epoch:  150 Loss: 0.55892 Acc: 0.741 Acc Dev: 0.725 F1 Dev: 0.586 p Dev: 0.696 r Dev: 0.505\n",
            "Epoch:  155 Loss: 0.56108 Acc: 0.740 Acc Dev: 0.728 F1 Dev: 0.610 p Dev: 0.678 r Dev: 0.555\n",
            "Epoch:  160 Loss: 0.56601 Acc: 0.734 Acc Dev: 0.729 F1 Dev: 0.606 p Dev: 0.686 r Dev: 0.542\n",
            "Epoch:  165 Loss: 0.56511 Acc: 0.732 Acc Dev: 0.730 F1 Dev: 0.592 p Dev: 0.707 r Dev: 0.509\n",
            "Epoch:  170 Loss: 0.55490 Acc: 0.751 Acc Dev: 0.736 F1 Dev: 0.625 p Dev: 0.688 r Dev: 0.573\n",
            "Epoch:  175 Loss: 0.55712 Acc: 0.744 Acc Dev: 0.730 F1 Dev: 0.594 p Dev: 0.703 r Dev: 0.514\n",
            "Epoch:  180 Loss: 0.56406 Acc: 0.730 Acc Dev: 0.727 F1 Dev: 0.587 p Dev: 0.702 r Dev: 0.505\n",
            "Epoch:  185 Loss: 0.55871 Acc: 0.743 Acc Dev: 0.734 F1 Dev: 0.637 p Dev: 0.670 r Dev: 0.607\n",
            "Epoch:  190 Loss: 0.56156 Acc: 0.738 Acc Dev: 0.729 F1 Dev: 0.577 p Dev: 0.721 r Dev: 0.481\n",
            "Epoch:  195 Loss: 0.55880 Acc: 0.735 Acc Dev: 0.734 F1 Dev: 0.619 p Dev: 0.690 r Dev: 0.562\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckhYanhOGJIr",
        "colab_type": "text"
      },
      "source": [
        "# ConvNets\n",
        "\n",
        "In pytorch a convolutional layer is defined as:\n",
        "```\n",
        "nn.Conv2d(<number of input chanels>, <number of filters>, kernel_size)\n",
        "```\n",
        "$\\text{number of input chanels}$ - The depth, in our case always 1\n",
        "\n",
        "$\\text{kernel_size}$ - is a touple setting the **height** $x$ **width** of a kernel. In our case the kernel will be of size (n, embedding_size) where 'n' is the number of words or pattern length. \n",
        "\n",
        "\n",
        "### We are going to create three independent conv blocks, stack the output and add a fc layer onto that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9NHJ4bHAVdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, embeddings):\n",
        "    super(Net, self).__init__()\n",
        "    # Get the required sizes\n",
        "    vocab_size = len(embeddings)\n",
        "    embedding_size = len(embeddings[0])\n",
        "    # Initialize embeddings\n",
        "    self.embeddings = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.embeddings.load_state_dict({'weight': embeddings})\n",
        "    # Disable training for the embeddings - IMPORTANT\n",
        "    self.embeddings.weight.requires_grad = False\n",
        "\n",
        "    # Set the number of filters\n",
        "    n_filters = 128\n",
        "    # Create 3 different kernel sizes\n",
        "    k1 = (2, embedding_size)\n",
        "    k2 = (3, embedding_size)\n",
        "    k3 = (4, embedding_size)\n",
        "\n",
        "    # TODO: Create three conv layers\n",
        "    self.conv1 = nn.Conv2d(1, n_filters, k1)\n",
        "    self.conv2 = nn.Conv2d(1, n_filters, k2)\n",
        "    self.conv3 = nn.Conv2d(1, n_filters, k3)\n",
        "\n",
        "    # The fully connected\n",
        "    self.fc1 = nn.Linear(3 * n_filters, 2)\n",
        "    # Add some dropout as always\n",
        "    self.d1 = nn.Dropout(0.5)\n",
        "\n",
        "  def conv_block(self, input, conv):\n",
        "    out = conv(input)\n",
        "    out = F.relu(out.squeeze(3))\n",
        "    out = F.max_pool1d(out, out.size()[2]).squeeze(2)\n",
        "    return out\n",
        "\n",
        "  def forward(self, x, lns=0):\n",
        "    # Embed the input: from id -> vec\n",
        "    x = self.embeddings(x) # x.shape = batch_size x sequence_length x emb_size\n",
        "    \n",
        "    # Add a dimension at '1'\n",
        "    x = x.unsqueeze(1) # Because the expected shape = batch_size x channels x sequence_length x emb_size\n",
        "    \n",
        "    # Get the three outputs from conv layers\n",
        "    x1 = self.conv_block(x, self.conv1)\n",
        "    x2 = self.conv_block(x, self.conv2)\n",
        "    x3 = self.conv_block(x, self.conv3)\n",
        "\n",
        "    x_all = torch.cat((x1, x2, x3), 1)\n",
        "    x_all = self.d1(x_all)\n",
        "    logits = self.fc1(x_all)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laylNHAgCEVw",
        "colab_type": "code",
        "outputId": "46e04fa7-62b1-4c8d-e1df-da2a9a5bac6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Device\n",
        "device = torch.device(DEVICE)\n",
        "# Create the network and get CE loss\n",
        "net = Net(embeddings)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# We don't want parameters that don't require a grad in the optimizer\n",
        "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "print(parameters)\n",
        "#TODO: Switch optimizer to Adam and set lr=0.001\n",
        "optimizer = optim.Adam(parameters, lr=0.001)\n",
        "# Move the net to the device\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<filter object at 0x7fa6844580b8>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embeddings): Embedding(1193516, 200)\n",
              "  (conv1): Conv2d(1, 128, kernel_size=(2, 200), stride=(1, 1))\n",
              "  (conv2): Conv2d(1, 128, kernel_size=(3, 200), stride=(1, 1))\n",
              "  (conv3): Conv2d(1, 128, kernel_size=(4, 200), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (d1): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btkiKjw0CHVJ",
        "colab_type": "code",
        "outputId": "d74ae094-b0ec-4bc7-f796-56b587c53e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "device = torch.device(DEVICE)\n",
        "# Move data to the right device only test, train is in batches\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "losses = []\n",
        "accs = []\n",
        "accs_dev = []\n",
        "\n",
        "batch_size = 1000\n",
        "\n",
        "num_batches = int(np.ceil(len(x_train) / batch_size))\n",
        "for epoch in range(200):\n",
        "  net.train()\n",
        "\n",
        "  # Create the running loss array\n",
        "  running_loss = []\n",
        "  for i in range(num_batches):\n",
        "    start = i * batch_size\n",
        "    end = (i+1) * batch_size\n",
        "    \n",
        "    x_train_batch = x_train[start:end] \n",
        "    y_train_batch = y_train[start:end] \n",
        "    l_train_batch = l_train[start:end]\n",
        "\n",
        "    # TODO: Move the batches to the right device\n",
        "    x_train_batch = x_train_batch.to(device)\n",
        "    y_train_batch = y_train_batch.to(device)\n",
        "    l_train_batch = l_train_batch.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(x_train_batch, l_train_batch)\n",
        "    loss = criterion(outputs, y_train_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Add the loss to the running_loss\n",
        "    running_loss.append(loss.item())\n",
        "\n",
        "  if epoch % 5 == 0:\n",
        "      net.eval()\n",
        "      outputs = net(x_train_batch, l_train_batch)\n",
        "      acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in torch.max(outputs, 1)[1].cpu().detach().numpy()], y_train_batch.cpu().numpy())\n",
        "\n",
        "      outputs_dev = net(x_test, l_test)\n",
        "      acc_dev = sklearn.metrics.accuracy_score(torch.max(outputs_dev, 1)[1].cpu().detach().numpy(), y_test.cpu().numpy())\n",
        "      f1_dev = f1_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      p_dev = precision_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      r_dev = recall_score(y_test.cpu().numpy(), torch.max(outputs_dev, 1)[1].cpu().detach().numpy())\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f} F1 Dev: {:.3f} p Dev: {:.3f} r Dev: {:.3f}\".format(epoch, np.average(running_loss), acc, acc_dev, f1_dev, p_dev, r_dev))\n",
        "      \n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0 Loss: 0.62839 Acc: 0.695 Acc Dev: 0.697 F1 Dev: 0.572 p Dev: 0.627 r Dev: 0.526\n",
            "Epoch:    5 Loss: 0.38459 Acc: 0.861 Acc Dev: 0.793 F1 Dev: 0.717 p Dev: 0.754 r Dev: 0.684\n",
            "Epoch:   10 Loss: 0.24001 Acc: 0.958 Acc Dev: 0.871 F1 Dev: 0.833 p Dev: 0.829 r Dev: 0.837\n",
            "Epoch:   15 Loss: 0.16532 Acc: 0.977 Acc Dev: 0.907 F1 Dev: 0.880 p Dev: 0.871 r Dev: 0.890\n",
            "Epoch:   20 Loss: 0.11662 Acc: 0.988 Acc Dev: 0.922 F1 Dev: 0.901 p Dev: 0.877 r Dev: 0.926\n",
            "Epoch:   25 Loss: 0.09321 Acc: 0.990 Acc Dev: 0.929 F1 Dev: 0.909 p Dev: 0.898 r Dev: 0.921\n",
            "Epoch:   30 Loss: 0.09388 Acc: 0.990 Acc Dev: 0.868 F1 Dev: 0.848 p Dev: 0.762 r Dev: 0.954\n",
            "Epoch:   35 Loss: 0.06395 Acc: 0.994 Acc Dev: 0.912 F1 Dev: 0.892 p Dev: 0.842 r Dev: 0.949\n",
            "Epoch:   40 Loss: 0.05193 Acc: 0.995 Acc Dev: 0.924 F1 Dev: 0.906 p Dev: 0.869 r Dev: 0.946\n",
            "Epoch:   45 Loss: 0.04786 Acc: 0.995 Acc Dev: 0.917 F1 Dev: 0.898 p Dev: 0.852 r Dev: 0.948\n",
            "Epoch:   50 Loss: 0.04322 Acc: 0.996 Acc Dev: 0.923 F1 Dev: 0.904 p Dev: 0.866 r Dev: 0.945\n",
            "Epoch:   55 Loss: 0.04107 Acc: 0.995 Acc Dev: 0.912 F1 Dev: 0.893 p Dev: 0.842 r Dev: 0.950\n",
            "Epoch:   60 Loss: 0.03808 Acc: 0.996 Acc Dev: 0.923 F1 Dev: 0.905 p Dev: 0.866 r Dev: 0.947\n",
            "Epoch:   65 Loss: 0.03610 Acc: 0.996 Acc Dev: 0.927 F1 Dev: 0.908 p Dev: 0.875 r Dev: 0.943\n",
            "Epoch:   70 Loss: 0.03462 Acc: 0.996 Acc Dev: 0.926 F1 Dev: 0.907 p Dev: 0.872 r Dev: 0.945\n",
            "Epoch:   75 Loss: 0.03309 Acc: 0.996 Acc Dev: 0.924 F1 Dev: 0.906 p Dev: 0.867 r Dev: 0.947\n",
            "Epoch:   80 Loss: 0.03042 Acc: 0.995 Acc Dev: 0.914 F1 Dev: 0.894 p Dev: 0.845 r Dev: 0.949\n",
            "Epoch:   85 Loss: 0.03076 Acc: 0.996 Acc Dev: 0.922 F1 Dev: 0.903 p Dev: 0.864 r Dev: 0.945\n",
            "Epoch:   90 Loss: 0.02876 Acc: 0.997 Acc Dev: 0.930 F1 Dev: 0.912 p Dev: 0.883 r Dev: 0.943\n",
            "Epoch:   95 Loss: 0.02874 Acc: 0.996 Acc Dev: 0.914 F1 Dev: 0.895 p Dev: 0.847 r Dev: 0.948\n",
            "Epoch:  100 Loss: 0.02652 Acc: 0.996 Acc Dev: 0.926 F1 Dev: 0.907 p Dev: 0.871 r Dev: 0.947\n",
            "Epoch:  105 Loss: 0.02708 Acc: 0.996 Acc Dev: 0.915 F1 Dev: 0.896 p Dev: 0.846 r Dev: 0.953\n",
            "Epoch:  110 Loss: 0.02447 Acc: 0.996 Acc Dev: 0.925 F1 Dev: 0.907 p Dev: 0.869 r Dev: 0.948\n",
            "Epoch:  115 Loss: 0.02670 Acc: 0.996 Acc Dev: 0.920 F1 Dev: 0.901 p Dev: 0.857 r Dev: 0.949\n",
            "Epoch:  120 Loss: 0.02414 Acc: 0.996 Acc Dev: 0.925 F1 Dev: 0.907 p Dev: 0.870 r Dev: 0.946\n",
            "Epoch:  125 Loss: 0.02303 Acc: 0.996 Acc Dev: 0.913 F1 Dev: 0.894 p Dev: 0.845 r Dev: 0.949\n",
            "Epoch:  130 Loss: 0.02262 Acc: 0.996 Acc Dev: 0.925 F1 Dev: 0.907 p Dev: 0.869 r Dev: 0.947\n",
            "Epoch:  135 Loss: 0.02316 Acc: 0.996 Acc Dev: 0.931 F1 Dev: 0.912 p Dev: 0.885 r Dev: 0.942\n",
            "Epoch:  140 Loss: 0.02375 Acc: 0.996 Acc Dev: 0.921 F1 Dev: 0.902 p Dev: 0.860 r Dev: 0.947\n",
            "Epoch:  145 Loss: 0.02198 Acc: 0.996 Acc Dev: 0.909 F1 Dev: 0.889 p Dev: 0.835 r Dev: 0.950\n",
            "Epoch:  150 Loss: 0.02301 Acc: 0.996 Acc Dev: 0.917 F1 Dev: 0.898 p Dev: 0.853 r Dev: 0.949\n",
            "Epoch:  155 Loss: 0.02295 Acc: 0.996 Acc Dev: 0.913 F1 Dev: 0.893 p Dev: 0.843 r Dev: 0.950\n",
            "Epoch:  160 Loss: 0.02270 Acc: 0.996 Acc Dev: 0.919 F1 Dev: 0.900 p Dev: 0.856 r Dev: 0.949\n",
            "Epoch:  165 Loss: 0.02188 Acc: 0.996 Acc Dev: 0.927 F1 Dev: 0.909 p Dev: 0.877 r Dev: 0.943\n",
            "Epoch:  170 Loss: 0.02128 Acc: 0.996 Acc Dev: 0.926 F1 Dev: 0.908 p Dev: 0.872 r Dev: 0.946\n",
            "Epoch:  175 Loss: 0.02165 Acc: 0.996 Acc Dev: 0.921 F1 Dev: 0.902 p Dev: 0.859 r Dev: 0.950\n",
            "Epoch:  180 Loss: 0.02285 Acc: 0.996 Acc Dev: 0.916 F1 Dev: 0.897 p Dev: 0.849 r Dev: 0.951\n",
            "Epoch:  185 Loss: 0.02085 Acc: 0.996 Acc Dev: 0.918 F1 Dev: 0.899 p Dev: 0.856 r Dev: 0.947\n",
            "Epoch:  190 Loss: 0.02116 Acc: 0.996 Acc Dev: 0.912 F1 Dev: 0.892 p Dev: 0.840 r Dev: 0.951\n",
            "Epoch:  195 Loss: 0.01891 Acc: 0.996 Acc Dev: 0.920 F1 Dev: 0.900 p Dev: 0.863 r Dev: 0.941\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8sUYqDAER_a",
        "colab_type": "code",
        "outputId": "d08595b3-224f-44ff-d9a9-b2a3cc6a5d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tweet = \"What a shitty day\"\n",
        "print(tweet)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What a shitty day\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4fwgt-GJ2KO",
        "colab_type": "code",
        "outputId": "aad3ab64-9b8f-43b0-972b-771742a704aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tkns = [tkn.lower_ for tkn in nlp.tokenizer(tweet) if not tkn.is_punct and\n",
        "          len(tkn.lower_.strip()) > 0]\n",
        "print(tkns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', 'a', 'shitty', 'day']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB1pCz_aKCfQ",
        "colab_type": "code",
        "outputId": "456144f9-cd5d-4448-d890-6a3a849b2f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert tokens to indices \n",
        "inds = [word2id.get(tkn, word2id.get(\"<UNK>\")) for tkn in tkns]\n",
        "print(inds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[86, 11, 5226, 125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrXegU2fKNOE",
        "colab_type": "code",
        "outputId": "3ad39ac9-602f-4d4d-f04b-79fe14809694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Add padding to match len(inds) == 40\n",
        "inds.extend([word2id['<PAD>']] * (MAX_SEQ_LEN - len(inds)))\n",
        "print(inds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[86, 11, 5226, 125, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AydPv2LdKdYT",
        "colab_type": "code",
        "outputId": "a69c7c4c-9a49-490e-dc3e-882d26bfdc9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Move to torch\n",
        "inds = torch.tensor([inds]).to(device)\n",
        "print(inds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[     86,      11,    5226,     125, 1193515, 1193515, 1193515, 1193515,\n",
            "         1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515,\n",
            "         1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515,\n",
            "         1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515,\n",
            "         1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515, 1193515]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN41G8fEK2LC",
        "colab_type": "code",
        "outputId": "d28048a4-a2c3-483e-e493-51337aae2746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Predict\n",
        "net.eval()\n",
        "torch.softmax(net(inds, 0), dim=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9918, 0.0082]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As9wtdjtLzM6",
        "colab_type": "text"
      },
      "source": [
        "# Find where mistakes are made in the test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHV3C6FOb7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Get all predictions for x_test and apply softmax\n",
        "out = torch.softmax(net(x_test, 0), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJeJ0Fs7OglU",
        "colab_type": "code",
        "outputId": "a77da461-1963-4362-ad46-e55533efd559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Find a couple of examples where the Net is sure it is correct\n",
        "out = out.detach().cpu().numpy()\n",
        "for i in range(200):\n",
        "  pred = np.argmax(out[i])\n",
        "  if pred != y_test[i] and out[i][pred] > 0.9:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "40\n",
            "78\n",
            "105\n",
            "124\n",
            "151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUo4rUkIO_E2",
        "colab_type": "code",
        "outputId": "5a1ba96b-42f0-4975-93f5-a5266a466e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Print the examples\n",
        "ind = 105\n",
        "print(y_test[ind])\n",
        "print(out[ind])\n",
        "print(\" \".join([id2word[i] for i in x_test[ind].cpu().detach().numpy() if id2word[i] != '<PAD>']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0, device='cuda:0')\n",
            "[1.1734356e-04 9.9988270e-01]\n",
            "are you a sore loser\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ2628EvPK5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}