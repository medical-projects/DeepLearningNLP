{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass & Adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdjVtLYL6sXJ",
        "colab_type": "text"
      },
      "source": [
        "#Sentiment Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_QSfQu7arNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SWITCH TO GPU\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import torch \n",
        "\n",
        "SEED = 15\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X42qEQjcP5Cj",
        "colab_type": "text"
      },
      "source": [
        "# Find index of the maximum value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32GCDIPOx3f",
        "colab_type": "code",
        "outputId": "061ebd59-21e3-4859-c94a-b9e75d14a9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.tensor([[0.5, 0.7], [0.3, 0.1]])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 0.7000],\n",
            "        [0.3000, 0.1000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEhWWk7yOyNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Use torch max to calculate the maximum value in each row\n",
        "#print(torch.max(x, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4lXNDq6njd",
        "colab_type": "text"
      },
      "source": [
        "# Get the data from github "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0g6YMvNcFUA",
        "colab_type": "code",
        "outputId": "382fc046-fdd6-4e64-cda6-4e3a3548143b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/w-is-h/tmp/master/dataset.csv\", encoding='cp1252')\n",
        "x = df['SentimentText'].values[0:6000]\n",
        "y = df['Sentiment'].values[0:6000]\n",
        "print(y)\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 ... 1 1 0]\n",
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I9rNmcu6fpZ",
        "colab_type": "code",
        "outputId": "e7c70d2e-8b17-438d-bd41-1048e296bdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Remove mails and https links\n",
        "pat_1 = r\"(?:\\@|https?\\://)\\S+\"\n",
        "# Remove tags\n",
        "pat_2 = r'#\\w+ ?'\n",
        "# Combine into one regex\n",
        "combined_pat = r'|'.join((pat_1, pat_2))\n",
        "# Remove websites\n",
        "www_pat = r'www.[^ ]+'\n",
        "# Remove HTML tags\n",
        "html_tag = r'<[^>]+>'\n",
        "def data_cleaner(text):\n",
        "  cleantags = \"\"\n",
        "  try:\n",
        "    stripped = re.sub(combined_pat, '', text)\n",
        "    stripped = re.sub(www_pat, '', stripped)\n",
        "    cleantags = re.sub(html_tag, '', stripped)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    cleantags = \"None\"\n",
        "  return cleantags\n",
        "\n",
        "x_original = x\n",
        "x = [data_cleaner(review) for review in x]\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "first think another Disney movie, might good, it's kids movie. watch it, can't help enjoy it. ages love movie. first saw movie 10 8 years later still love it! Danny Glover superb could play part better. Christopher Lloyd hilarious perfect part. Tony Danza believable Mel Clark. can't help, enjoy movie! give 10/10!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z75yCgk-7wLa",
        "colab_type": "text"
      },
      "source": [
        "# SpaCy\n",
        "\n",
        "We can use spacy to tokenize the text and further clean it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmE8oH7KbonG",
        "colab_type": "code",
        "outputId": "cbc64367-0b8b-4f68-f8ff-dd88057d05f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.attrs import LOWER\n",
        "# Load the english model for spacy, the disable part is used to make it faster\n",
        "nlp = spacy.load('en', disable=['ner', 'parser'])\n",
        "\n",
        "tok_snts = []\n",
        "for snt in x:\n",
        "  tkns = [tkn.lemma_.lower() for tkn in nlp.tokenizer(snt) if not tkn.is_punct]\n",
        "  tok_snts.append(tkns)\n",
        "# Save back\n",
        "x = tok_snts\n",
        "# Print the first sentence\n",
        "print(x[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeff1', 'think', 'another', 'disney', 'movie', 'may', 'good', '-pron-', 'have', 'kid', 'movie', 'watch', 'it', 'can', 'not', 'help', 'enjoy', 'it', 'age', 'love', 'movie', '\\ufeff1', 'see', 'movie', '10', '8', 'year', 'late', 'still', 'love', 'it', 'danny', 'glover', 'superb', 'can', 'play', 'part', 'well', 'christopher', 'lloyd', 'hilarious', 'perfect', 'part', 'tony', 'danza', 'believable', 'mel', 'clark', 'can', 'not', 'help', 'enjoy', 'movie', 'give', '10/10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkRb0cGDJqYh",
        "colab_type": "code",
        "outputId": "ed1fe245-0fac-4ebf-ef8c-0d7ab2cecc60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v = Word2Vec(x, size=300, window=6, min_count=4, workers=4)\n",
        "w2v.wv.most_similar(\"bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('funny', 0.8754518032073975),\n",
              " ('pretty', 0.8673598766326904),\n",
              " (\"it's\", 0.8553382158279419),\n",
              " ('stupid', 0.8540974855422974),\n",
              " ('plain', 0.8357093334197998),\n",
              " ('yes', 0.8318045139312744),\n",
              " ('cool', 0.8311686515808105),\n",
              " ('ok', 0.830740749835968),\n",
              " ('okay', 0.8268406391143799),\n",
              " ('horrible', 0.8229296207427979)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZsis4V88i-",
        "colab_type": "text"
      },
      "source": [
        "# Convert each sentence into the average sum of the vector representations of its tokens\n",
        "\n",
        "Save the results into a new variable x_emb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTQktTzBdaYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_emb - embedded sentences\n",
        "x_emb = np.zeros((len(x), 300))\n",
        "# Loop over sentences\n",
        "for i_snt, snt in enumerate(x):\n",
        "  cnt = 0\n",
        "  # Loop over the words of a sentence\n",
        "  for i_word, word in enumerate(snt):\n",
        "    if word in w2v.wv:\n",
        "      x_emb[i_snt] += w2v.wv.get_vector(word)\n",
        "      cnt += 1\n",
        "  if cnt > 0:\n",
        "    x_emb[i_snt] = x_emb[i_snt] / cnt\n",
        "# Save the originals, will be needd later\n",
        "x_or = x_emb\n",
        "y_or = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATUWE2b9VKd",
        "colab_type": "text"
      },
      "source": [
        "# Split the dataset into train/test - USE SKLEARN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kpy4rEGnghM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_emb, y, test_size=0.2, random_state=SEED)\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZH3ssL6_dK4",
        "colab_type": "text"
      },
      "source": [
        "#Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDb8Wz0m2PU",
        "colab_type": "code",
        "outputId": "a351f06d-0249-4ee0-feca-a47e6e715d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Get torch stuff\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics\n",
        "\n",
        "device = torch.device('cuda')\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      self.fc1 = nn.Linear(300, 100)\n",
        "      # TODO Switch from binary to multicalss with 2 classes\n",
        "      self.fc2 = nn.Linear(100, 2)\n",
        "      \n",
        "      self.d1 = nn.Dropout(0.5)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      x = self.d1(torch.relu(self.fc1(x)))\n",
        "      x = torch.sigmoid(self.fc2(x))\n",
        "      return x\n",
        "    \n",
        "net = Net()\n",
        "# TODO: Switch from Binary cross entropy to Cross Entropy\n",
        "criterion = nn.CrossEntropyLoss() #nn.BCELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.99)\n",
        "\n",
        "# TODO LATER: Switch to Adam\n",
        "#optimizer = optim.Adam(net.parameters(), lr=0.006)\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
              "  (d1): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E7VRuEb9bj1",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXYUTXUoS-t",
        "colab_type": "code",
        "outputId": "ff6044bb-b325-48be-948c-380c1e1803dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Move data to the right device\n",
        "x_train = x_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "x_test = x_train.to(device)\n",
        "y_test = y_train.to(device)\n",
        "\n",
        "print(\"IGNORE THE ACC - WE ARE USING A SMALL SUBESET OF THE DATA\")\n",
        "net.train()\n",
        "for epoch in range(5000): \n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(x_train)\n",
        "  loss = criterion(outputs, y_train)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  \n",
        "  # print statistics\n",
        "  if epoch % 500 == 0:\n",
        "      net.eval()\n",
        "      #TODO: the way we calculate the output is wrong, we can't use if x > 0.5, but have to use max index per row\n",
        "      #acc = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs.cpu().detach().numpy()], y_train.cpu().numpy())\n",
        "      outputs = torch.max(outputs, 1)[1]\n",
        "      acc = sklearn.metrics.accuracy_score(outputs.cpu().detach().numpy(), y_train.cpu().numpy())\n",
        "      \n",
        "      outputs_dev = net(x_test)\n",
        "      #TODO: Same for the dev accuracy\n",
        "      #acc_dev = sklearn.metrics.accuracy_score([1 if x > 0.5 else 0 for x in outputs_dev.cpu().detach().numpy()], y_dev.cpu().numpy())\n",
        "      outputs_dev = torch.max(outputs_dev, 1)[1]\n",
        "      acc_dev = sklearn.metrics.accuracy_score(outputs_dev.cpu().detach().numpy(), y_test.cpu().numpy())\n",
        "      \n",
        "      print(\"Epoch: {:4} Loss: {:.5f} Acc: {:.3f} Acc Dev: {:.3f}\".format(epoch, loss.item(), acc, acc_dev))\n",
        "      net.train()\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IGNORE THE ACC - WE ARE USING A SMALL SUBESET OF THE DATA\n",
            "Epoch:    0 Loss: 0.69322 Acc: 0.510 Acc Dev: 0.510\n",
            "Epoch:  500 Loss: 0.55342 Acc: 0.746 Acc Dev: 0.753\n",
            "Epoch: 1000 Loss: 0.53806 Acc: 0.767 Acc Dev: 0.777\n",
            "Epoch: 1500 Loss: 0.52300 Acc: 0.781 Acc Dev: 0.794\n",
            "Epoch: 2000 Loss: 0.51873 Acc: 0.789 Acc Dev: 0.800\n",
            "Epoch: 2500 Loss: 0.52207 Acc: 0.782 Acc Dev: 0.802\n",
            "Epoch: 3000 Loss: 0.51813 Acc: 0.790 Acc Dev: 0.805\n",
            "Epoch: 3500 Loss: 0.51918 Acc: 0.782 Acc Dev: 0.805\n",
            "Epoch: 4000 Loss: 0.52331 Acc: 0.781 Acc Dev: 0.800\n",
            "Epoch: 4500 Loss: 0.52825 Acc: 0.773 Acc Dev: 0.792\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B5bFRUwHLcT",
        "colab_type": "code",
        "outputId": "919f478e-3f89-4f64-a60c-295a714f14e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(outputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.2199e-01, 7.7617e-01],\n",
            "        [2.4514e-03, 9.9758e-01],\n",
            "        [3.5216e-02, 9.6457e-01],\n",
            "        ...,\n",
            "        [7.8378e-05, 9.9992e-01],\n",
            "        [1.3793e-01, 8.6082e-01],\n",
            "        [1.0000e+00, 1.7635e-07]], device='cuda:0', grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}